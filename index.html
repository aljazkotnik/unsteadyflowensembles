<!DOCTYPE html>

<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <title>Harnessing Spatial Representations</title>
  
  <link rel="icon" type="image/x-icon" href="/favicon.ico"/>
  
  <link rel="stylesheet" href="/harnessingspacewebsite/style/ieee_webpage.css">
  
  

  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Condensed&family=Roboto:wght@300&display=swap" rel="stylesheet">
  
  <link rel="stylesheet" href="/harnessingspacewebsite/style/font-awesome_4.7.0.min.css">
  
</head>

<body>


<h1>INTERACTIVE DISCOVERY OF CAUSE-EFFECT
RELATIONSHIPS</h1>

  <div>

	<p>Discovering cause-and-effect relationships, the links between input parameters to an experiment or simulation and the observed outcome, is fundamental to the scientific process. An understanding of the underlying mechanisms responsible for these connections is the key transferable learning to be derived. In many cases, data collected to study these mechanisms is best represented by images. The scientistâ€™s domain knowledge is crucial for image interpretation and in cases where results contain large numbers of images, the necessary human-data interaction becomes the bottleneck of the analysis and discovery process. To accelerate this step, we propose a conceptual framework to reduce the number of detailed image analyses and comparisons required to gain a full understanding of cause-and-effect relationships.</p>

  </div>


<h2><span>Harnessing Spatial Encodings</span></h2>

  <div>
  
    <div>
	  <figure>
	    <img style="max-width: 45%;" src="/harnessingspacewebsite/images/correlations.png" alt="alt1">
		
	    <img style="max-width: 45%;" src="/harnessingspacewebsite/images/knowledge_capture.png" alt="alt2">
	  </figure>
	</div>

	<p>Our approach allows scientists to visually encode their interpretation of an image set by interactively manipulating the on-screen location of the images. To identify cause-and-effect relationships, this spatial arrangement is then correlated with the input and outcome metadata associated with each image.</p>

	<p>A variety of tools to meaningfully group images, capture knowledge represented by the groups, and establish the representative behavior of a group and its variability, are incorporated to provide guidance to the practitioner and accelerate the process.</p>

  </div>

<h2><span>Example Cases</span></h2>

  <div>

	<p>We illustrate the utility of the framework with examples including classification of images using machine learning, analysis of metal micro-structures in material science and engineering simulations of the flow around airfoils.</p>
	
	<div>
	  <figure>
	    <a href="/harnessingspacewebsite/examples/airfoils/airfoils.html" style="text-decoration: none;">
	      <img src="/harnessingspacewebsite/images/airfoils_thumbnail.png" alt="alt1">
	    </a>
		
		<a href="/harnessingspacewebsite/examples/animals/animals.html" style="text-decoration: none;">
	      <img src="/harnessingspacewebsite/images/animals_thumbnail.png" alt="alt2">
	    </a>
	  
	    <img src="/harnessingspacewebsite/images/placeholder.png" alt="alt3">
	  </figure>
	</div>
	
	
  </div>




<h2><span>Draft Publication</span></h2>

  <div>

	<article>
	  
	  <h4>
		<a href="/harnessingspacewebsite/IEEE_Harnessing_Spatial_Representations_of_Image_Collections_in_the_Discovery_of_Cause-and-Effect Relationships_in_Data.pdf" target="_blank" slot="title"><b>Harnessing Spatial Representations of Image Collections in the Discovery of Cause-And-Effect Relationships in Data</b></a>
	  </h4>
	  <p>Aljaz Kotnik and Graham Pullan</p>
	  <p>Submitted to IEEE VIS 2021</p>
	</article>

  </div>

<h2><span>Code & Data</span></h2>


  <div>

	<b>All the code is available on GitHub:</b>

	<ul>
	  <li>
		<i class="fa fa-github"></i>
		<a href="https://github.com/aljazkotnik/harnessingspace" target="_blank">github.com/aljazkotnik/harnessingspace</a>
	  </li>
	</ul>


	<b>For the demos we used data from the following sources:</b>

	<ul class="no-list-style">
	  <li>
		<i class="fa fa-database"></i>
		<a href="https://github.com/aljazkotnik/harnessingspace/tree/main/data/xfoil2d" target="_blank">Airfoil data available at our GitHub</a>
	  </li>
	  
	  <li>
		<i class="fa fa-database"></i>
		<a href="https://www.kaggle.com/alessiocorrado99/animals10" target="_blank">Animals10 images hosted by Kaggle</a>
	  </li>
	  
	  <li>
		<i class="fa fa-database"></i>
		<a href="https://materialsdata.nist.gov/handle/11256/940" target="_blank">Steel micrography data by DeCost et al. 2017</a>
	  </li>
	</ul>

  </div>


<h2><span>Authors</span></h2>

  <div>

	<ol class="no-list-style">
	  <li>
		<div>
		  <h4 class="author-name">
			<span slot="name">Aljaz Kotnik</span>
		  </h4>
		  <div>
			<span slot="affiliation">University of Cambridge<br>Whittle Laboratory</span>
		  </div>
		  <div>
			<span>
			  <i class="fa fa-github"></i>
			  <a href="https://github.com/aljazkotnik" target="_blank" slot="github">aljazkotnik</a>
			</span>
		  </div>
		</div>
	  </li>
	  
	  <li>
		<div>
		  <h4 class="author-name">
			<span slot="name">Graham Pullan</span>
		  </h4>
		  <div>
			<span slot="affiliation">University of Cambridge<br>Whittle Laboratory</span>
		  </div>
		  <div>
			<span>
			  <i class="fa fa-globe"></i>
			  <a href="https://whittle.eng.cam.ac.uk/lab/team/graham-pullan/" target="_blank" slot="website">Graham @ Whittle Laboratory</a>
			</span>
			<span>
			  <i class="fa fa-twitter"></i>
			  <a href="https://twitter.com/grahampullan" target="_blank" slot="twitter">grahampullan</a>
			</span>
			<span>
			  <i class="fa fa-github"></i>
			  <a href="https://github.com/grahampullan" target="_blank" slot="github">grahampullan</a>
			</span>
		  </div>
		</div>
	  </li>
	</ol>

  </div>

</body>

</html>